{"cells":[{"cell_type":"markdown","id":"c79a760b-d438-41bb-b1a1-2578773c0fe0","metadata":{},"source":["![wordcloud](wordcloud.png)\n","\n","As a Data Scientist working for a mobile app company, you usually find yourself applying product analytics to better understand user behavior, uncover patterns, and reveal insights to identify the great and not-so-great features. Recently, the number of negative reviews has increased on Google Play, and as a consequence, the app's rating has been decreasing. The team has requested you to analyze the situation and make sense of the negative reviews.\n","\n","It's up to you to apply K-means clustering from scikit-learn and NLP techniques through NLTK to sort text data from negative reviews in the Google Play Store into categories!\n","\n","## The Data\n","\n","A dataset has been shared with a sample of reviews and their respective scores (from 1 to 5) in the Google Play Store. A summary and preview are provided below.\n","\n","# reviews.csv\n","\n","| Column     | Description              |\n","|------------|--------------------------|\n","| `'content'` | Content (text) of each review. |\n","| `'score'` | Score assigned to the review by the user as an integer (from 1 to 5). |"]},{"cell_type":"markdown","id":"125d169f","metadata":{},"source":["To reveal the main topics from app reviews, you'll perform these tasks:\n","\n","- Preprocess the negative reviews (reviews with a score of 1 or 2) by tokenizing the text, removing stop words and non-alpha characters. Save the results in a pandas DataFrame called preprocessed_reviews.\n","- Vectorize the cleaned negative reviews using TF-IDF and store the matrix in a variable called tfidf_matrix.\n","- Apply K-means clustering to tfidf_matrix to group the reviews into five categories. Store the predicted labels in a list called categories.\n","- For each unique cluster label, find the most frequent term. Store the results in a pandas DataFrame called topic_terms with at least three columns to store the label assigned from K-means, the identified term, and its frequency."]},{"cell_type":"code","execution_count":1,"id":"48172b7a-d771-435b-a6fe-c99134ac5eba","metadata":{"executionCancelledAt":null,"executionTime":2549,"lastExecutedAt":1720631139848,"lastExecutedByKernel":"38fa4f9d-01e5-4acb-bf3b-15411647eebd","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize"},"outputs":[],"source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.cluster import KMeans\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize"]},{"cell_type":"code","execution_count":2,"id":"8a6577b0-9915-43c7-b1db-b0c106a71cca","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":101,"type":"stream"}}},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/repl/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Download necessary files from NLTK:\n","# punkt -> Tokenization\n","# stopwords -> Stop words removal\n","nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")"]},{"cell_type":"code","execution_count":3,"id":"7fbf3e3f-0526-4f53-908e-0bf9913f213d","metadata":{"executionCancelledAt":null,"executionTime":269,"lastExecutedAt":1720557074405,"lastExecutedByKernel":"5f98952b-fa90-414a-8856-39a68b3bdd75","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load the reviews dataset and preview it\nreviews = pd.read_csv('reviews.csv')\nreviews.head()","outputsMetadata":{"0":{"height":196,"type":"dataFrame"}}},"outputs":[{"data":{"application/com.datacamp.data-table.v2+json":{"table":{"data":{"content":["I cannot open the app anymore","I have been begging for a refund from this app for over a month and nobody is replying me","Very costly for the premium version (approx Indian Rupees 910 per year). Better to download the premium version of this app from apkmos website and use it. Microsoft to do list app is far more better.","Used to keep me organized, but all the 2020 UPDATES have made a mess of things !!! Y cudn't u leave well enuf alone ??? Guess ur techies feel the need to keep making changes to justify continuing to collect their salary !!! ðŸ¤¤ðŸ¤¤ðŸ¤¤","Dan Birthday Oct 28"],"index":[0,1,2,3,4],"score":[1,1,1,1,1]},"schema":{"fields":[{"name":"index","type":"integer"},{"name":"content","type":"string"},{"name":"score","type":"integer"}],"pandas_version":"1.4.0","primaryKey":["index"]}},"total_rows":5,"truncation_type":null},"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I cannot open the app anymore</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I have been begging for a refund from this app...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Very costly for the premium version (approx In...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Used to keep me organized, but all the 2020 UP...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Dan Birthday Oct 28</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             content  score\n","0                      I cannot open the app anymore      1\n","1  I have been begging for a refund from this app...      1\n","2  Very costly for the premium version (approx In...      1\n","3  Used to keep me organized, but all the 2020 UP...      1\n","4                                Dan Birthday Oct 28      1"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Load the reviews dataset and preview it\n","reviews = pd.read_csv(\"reviews.csv\")\n","reviews.head()"]},{"cell_type":"code","execution_count":4,"id":"3b2697f7-e85a-4a11-bfbb-59af07b89c75","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1720557076395,"lastExecutedByKernel":"5f98952b-fa90-414a-8856-39a68b3bdd75","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Your code starts here\n# Cells are free! Use as many as you need ;)"},"outputs":[],"source":["# Your code starts here\n","# Cells are free! Use as many as you need ;)"]},{"cell_type":"markdown","id":"1d36c9da","metadata":{},"source":["# Solution"]},{"cell_type":"code","execution_count":null,"id":"19f797a6","metadata":{},"outputs":[],"source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.cluster import KMeans\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","# Download necessary files from NLTK:\n","# punkt -> Tokenization\n","# stopwords -> Stop words removal\n","nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")\n","\n","# Load the reviews dataset and preview it\n","reviews = pd.read_csv(\"reviews.csv\")\n","reviews.head()\n","\n","# Step 1: Preprocess the negative reviews\n","\n","# Filter negative reviews (having a score of 1 or 2)\n","negative_reviews_tmp = reviews[(reviews[\"score\"] == 1) | (reviews[\"score\"] == 2)][\"content\"]\n","\n","def preprocess_text(text):\n","    \"\"\"Performs all the required steps in the text preprocessing\"\"\"\n","\n","    # Tokenizing the text\n","    tokens = word_tokenize(text)\n","\n","    # Removing stop words and non-alpha characters\n","    filtered_tokens = [\n","        token\n","        for token in tokens\n","        if token.isalpha() and token.lower() not in stopwords.words(\"english\")\n","    ]\n","\n","    return \" \".join(filtered_tokens)\n","\n","\n","# Apply the preprocessing function to the negative reviews\n","negative_reviews_cleaned = negative_reviews_tmp.apply(preprocess_text)\n","\n","# Store the preprocessed negative reviews in a pandas DataFrame\n","preprocessed_reviews = pd.DataFrame({\"review\": negative_reviews_cleaned})\n","preprocessed_reviews.head()\n","\n","# Step 2: Vectorize the cleaned negative reviews using TF-IDF\n","\n","# Vectorize the cleaned reviews using TF-IDF\n","vectorizer = TfidfVectorizer()\n","tfidf_matrix = vectorizer.fit_transform(preprocessed_reviews[\"review\"])\n","\n","# Step 3: Apply K-means clustering to tfidf_matrix\n","\n","# Apply K-means clustering (store the model as clust_kmeans)\n","clust_kmeans = KMeans(n_clusters=5, random_state=500)\n","pred_labels = clust_kmeans.fit_predict(tfidf_matrix)\n","\n","# Store the predicted labels in a list variable called categories\n","categories = pred_labels.tolist()\n","preprocessed_reviews[\"category\"] = categories\n","\n","# Step 4: For each unique cluster label, find the most frequent term\n","\n","# Get the feature names (terms) from the vectorizer\n","terms = vectorizer.get_feature_names_out()\n","\n","# List to save the top term for each cluster\n","topic_terms_list = []\n","\n","for cluster in range(clust_kmeans.n_clusters):\n","    # Get indices of reviews in the current cluster\n","    cluster_indices = [i for i, label in enumerate(categories) if label == cluster]\n","\n","    # Sum the tf-idf scores for each term in the cluster\n","    cluster_tfidf_sum = tfidf_matrix[cluster_indices].sum(axis=0)\n","    cluster_term_freq = np.asarray(cluster_tfidf_sum).ravel()\n","\n","    # Get the top term and its frequencies\n","    top_term_index = cluster_term_freq.argsort()[::-1][0]\n","\n","    # Append rows to the topic_terms DataFrame with three fields:\n","    # - category: label / cluster assigned from K-means\n","    # - term: the identified top term\n","    # - frequency: term's weight for the category\n","    topic_terms_list.append(\n","        {\n","            \"category\": cluster,\n","            \"term\": terms[top_term_index],\n","            \"frequency\": cluster_term_freq[top_term_index],\n","        }\n","    )\n","\n","# Pandas DataFrame to store results from this step\n","topic_terms = pd.DataFrame(topic_terms_list)\n","\n","# Output the final result\n","print(topic_terms)\n"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
